{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ProphetNetForConditionalGeneration, ProphetNetTokenizer, ProphetNetEncoder\n",
    "\n",
    "model_raw = ProphetNetForConditionalGeneration.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n",
    "model = ProphetNetForConditionalGeneration.from_pretrained(\"microsoft/prophetnet-large-uncased\")\n",
    "tokenizer = ProphetNetTokenizer.from_pretrained(\"microsoft/prophetnet-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "text = torch.load('../../data/processed/cnn-dm/text/test/chunk_0.pt')\n",
    "summary = torch.load('../../data/processed/cnn-dm/summary/test/chunk_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sd = torch.load('../../models/unfrozen-cnn/epoch0_end', map_location=torch.device('cpu'))\n",
    "input_ids = text.input_ids[:1]\n",
    "attention_mask = text.attention_mask[:1]\n",
    "labels = summary.input_ids[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sd = {key[13:]: value for key, value in sd.items()}\n",
    "model.load_state_dict(new_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'costa rica has taken its border dispute with nicaragua to international court repeating claims that its territory has been invaded in a statement thursday costa ricas foreign ministry said the country had filed a lawsuit at the international court of justice in the hague netherlands to end a situation that threatens imminent and irreparable harm to costa rica the suit asks the court to stop the construction of a canal on costa rican soil according to the statement tensions between nicaragua and costa rica have flared over calero island a parcel of land on the atlantic coast nicaragua denies its troops are in costa rican territory costa rica claims it has been invaded costa rica claims that in addition to the nicaraguan troops a dredging project in the river is dumping sediment on its side of the border and that a costa rican flag in the area was replaced with a nicaraguan flag nicaragua has accused costa rica of breaking diplomatic relations between the countries also thursday the organization of american states approved a resolution convening a meeting of ministers of foreign affairs to discuss the situation on december'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'costa ricas foreign ministry says the situation threatens imminent and irreparable harm the suit asks the court to stop the construction of a canal on costa rican soil foreign ministers from the region will discuss the situation december'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(labels[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated based on input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[SEP] according to the statement the suit asks the court to stop the construction of a canal on costa rican soil to end a situation that threatens imminent harm to costa rica and its citizens to end the situation that is threatening costa rica's sovereignty and to costa ricans to stop it from happening costa rica has taken a lawsuit at the international court of justice in the hague [SEP]\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_raw.generate(input_ids=input_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] costa ricas foreign ministry says it has filed a lawsuit at the international court of justice in the hague netherlands to end a situation that threatens imminent and irreparable harm to costa rica the suit asks the court to stop the construction of a canal on costa rican soil [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(input_ids=input_ids)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate based on encoder outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_outputs = model_raw.prophetnet.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "enc_outputs2 = model.prophetnet.encoder(input_ids=input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] to be continued. [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_raw.generate(encoder_outputs=enc_outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] new new york city is set to be a new city for the first time in years the city of new york will be the first to be built in the new town of st louis it is one of the most popular places in the world to be set up for a new town the city is now known as the town of the new city of the world has been set up with a new set of buildings and a new one that will be built on the site of the first of the three stages of the road that will go through the middle of the country and go through a series of steps that will lead to a new area of the city which will be named the new york bridge and the new bridge will be'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(encoder_outputs=enc_outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] tensions between nicaragua and costa rica have flared over calero island a parcel of land on the atlantic coast the statement was translated by the national news agency. 1629. 1656. 1654. 1641. 1654 [SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_raw.generate(encoder_outputs=enc_outputs2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP] costa rica has filed a lawsuit at the international court of justice in the hague netherlands to end a situation that threatens irreparambling harm to the country [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(encoder_outputs=enc_outputs2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs2.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=torch.randn(1, 500, 1024) #hidden_states\n",
    "key_value_states=torch.randn(1, 500, 1024)#encoder_hidden_states\n",
    "key_value_states20=torch.randn(20, 500, 1024)#encoder_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shape(tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, 16, 64).transpose(1, 2).contiguous()\n",
    "proj = torch.nn.Linear(1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, tgt_len, hidden_size = hidden_states.size()\n",
    "is_cross_attention = key_value_states is not None\n",
    "\n",
    "query_states = proj(hidden_states) / (64**0.5)    # 64 = head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_states = _shape(proj(key_value_states), -1, batch_size)\n",
    "value_states = _shape(proj(key_value_states), -1, batch_size)\n",
    "key_states20 = _shape(proj(key_value_states20), -1, batch_size)\n",
    "value_states20 = _shape(proj(key_value_states20), -1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 500, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 10000, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_value = (key_states, value_states)\n",
    "past_key_value20 = (key_states20, value_states20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_shape = (batch_size * 16, -1, 64)\n",
    "query_states = _shape(query_states, tgt_len, batch_size).view(*proj_shape)\n",
    "key_states = key_states.view(*proj_shape)\n",
    "value_states = value_states.view(*proj_shape)\n",
    "key_states20 = key_states20.view(*proj_shape)\n",
    "value_states20 = value_states20.view(*proj_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 500, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10000, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 500, 500])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 500, 10000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights20 = torch.bmm(query_states, key_states20.transpose(1, 2))\n",
    "attn_weights20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1)\n",
    "attn_weights20 = torch.nn.functional.softmax(attn_weights20, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_probs = torch.nn.functional.dropout(\n",
    "        attn_weights,\n",
    "        training=False\n",
    "    )\n",
    "attn_probs20 = torch.nn.functional.dropout(\n",
    "        attn_weights20,\n",
    "        training=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = torch.bmm(attn_probs, value_states)\n",
    "attn_output20 = torch.bmm(attn_probs20, value_states20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 500, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 500, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're back to same shape without problems (line 755)\n",
    "\n",
    "https://github.com/huggingface/transformers/blob/v4.17.0/src/transformers/models/prophetnet/modeling_prophetnet.py#L755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def _shape(tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, 16, 64).transpose(1, 2).contiguous()\n",
    "proj = torch.nn.Linear(1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=torch.randn(1, 500, 1024) #hidden_states\n",
    "batch_size, tgt_len, hidden_size = hidden_states.size()\n",
    "query_states = proj(hidden_states) / (64**0.5)    # 64 = head_dim\n",
    "\n",
    "proj_shape = (batch_size * 16, -1, 64)\n",
    "query_states = _shape(query_states, tgt_len, batch_size).view(*proj_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_value_states=torch.randn(bs, 500, 1024) #encoder_hidden_states\n",
    "key_states = _shape(proj(key_value_states), -1, batch_size)\n",
    "value_states = _shape(proj(key_value_states), -1, batch_size)\n",
    "\n",
    "key_states = key_states.view(*proj_shape)\n",
    "value_states = value_states.view(*proj_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
    "attn_probs = torch.nn.functional.softmax(attn_weights, dim=-1)\n",
    "attn_output = torch.bmm(attn_probs, value_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = (\n",
    "    attn_output.view(batch_size, 16, tgt_len, 64)\n",
    "    .transpose(1, 2)\n",
    "    .reshape(batch_size, tgt_len, hidden_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: torch.Size([1, 500, 1024])     Encoder: torch.Size([1, 500, 1024])\n",
      "Query shape: torch.Size([16, 500, 64])\n",
      "Key/value shape: torch.Size([16, 500, 64])\n",
      "Attn_weights shape: torch.Size([16, 500, 500])\n",
      "Attn_output shape: torch.Size([16, 500, 64])\n",
      "Output shape: torch.Size([1, 500, 1024])\n",
      "Output: -15.079450607299805\n",
      "\n",
      "Target: torch.Size([1, 500, 1024])     Encoder: torch.Size([20, 500, 1024])\n",
      "Query shape: torch.Size([16, 500, 64])\n",
      "Key/value shape: torch.Size([16, 10000, 64])\n",
      "Attn_weights shape: torch.Size([16, 500, 10000])\n",
      "Attn_output shape: torch.Size([16, 500, 64])\n",
      "Output shape: torch.Size([1, 500, 1024])\n",
      "Output: -195.8182373046875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bs in [1, 20]:\n",
    "    hidden_states=torch.randn(1, 500, 1024) #hidden_states\n",
    "    batch_size, tgt_len, hidden_size = hidden_states.size()\n",
    "    key_value_states=torch.randn(bs, 500, 1024) #encoder_hidden_states\n",
    "    query_states = proj(hidden_states) / (64**0.5)    # 64 = head_dim\n",
    "\n",
    "    print(f'Target: {hidden_states.shape}     Encoder: {key_value_states.shape}')\n",
    "\n",
    "    key_states = _shape(proj(key_value_states), -1, batch_size)\n",
    "    value_states = _shape(proj(key_value_states), -1, batch_size)\n",
    "\n",
    "    proj_shape = (batch_size * 16, -1, 64)\n",
    "    query_states = _shape(query_states, tgt_len, batch_size).view(*proj_shape)\n",
    "    key_states = key_states.view(*proj_shape)\n",
    "    value_states = value_states.view(*proj_shape)\n",
    "    print(\"Query shape:\", query_states.shape)\n",
    "    print(\"Key/value shape:\", key_states.shape)\n",
    "\n",
    "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
    "    print(\"Attn_weights shape:\", attn_weights.shape)\n",
    "    attn_probs = torch.nn.functional.softmax(attn_weights, dim=-1)\n",
    "    attn_output = torch.bmm(attn_probs, value_states)\n",
    "    print(\"Attn_output shape:\", attn_output.shape)\n",
    "\n",
    "    attn_output = (\n",
    "        attn_output.view(batch_size, 16, tgt_len, 64)\n",
    "        .transpose(1, 2)\n",
    "        .reshape(batch_size, tgt_len, hidden_size)\n",
    "    )\n",
    "    print(\"Output shape:\", attn_output.shape)\n",
    "\n",
    "\n",
    "    print(f'Output: {attn_output.sum()}')\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32380576835e39faf244e42e2407d9c11a0310471d132d51dd55c697e32382b7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('raffle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
